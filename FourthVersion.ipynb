{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('train2016.csv', mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    noTrainingExamples = 5568 # number of items in csv...  \n",
    "    noColumns = 108 # how many columns will we store... \n",
    "    line_count = 0\n",
    "    outputs = np.zeros(noTrainingExamples)\n",
    "    matrices = np.zeros((noTrainingExamples, noColumns))\n",
    "    columnNames = np.empty([1,noColumns], dtype=object)\n",
    "    userIDs = np.empty([1,noTrainingExamples])\n",
    "    for row in csv_reader:\n",
    "            \n",
    "        matrix = np.zeros(noColumns)\n",
    "#             matrix[0] = float(row['YOB'])\n",
    "        userIDs[0,line_count] = row['USER_ID']\n",
    "        # YOB\n",
    "        columnNames[0,0] = 'YOB'\n",
    "        maxv = 0\n",
    "        try:\n",
    "            matrix[0] = (((float(row['YOB'])%1900)/100)-0.5)\n",
    "        except ValueError:\n",
    "            matrix[0] = -3\n",
    "        \n",
    "        # GENDER\n",
    "        columnNames[0,1] = 'Gender'\n",
    "        if 'Male' in row['Gender']:\n",
    "            matrix[1] = 1\n",
    "        elif 'Female' in row['Gender']:\n",
    "            matrix[1] = -1\n",
    "        else:\n",
    "            matrix[1] = -3\n",
    "        \n",
    "        #  [1 0.6 0.2 -0.2 -0.6]\n",
    "        #INCOME\n",
    "        columnNames[0,2] = 'Income'\n",
    "        if 'over $150,000' in row['Income']:\n",
    "            matrix[2] = 1\n",
    "        elif '$100,001 - $150,000' in row['Income']:\n",
    "            matrix[2] = 0.6\n",
    "        elif '$75,000 - $100,000' in row['Income']:\n",
    "            matrix[2] = 0.2\n",
    "        elif '$50,000 - $74,999' in row['Income']:\n",
    "            matrix[2] = -0.2\n",
    "        elif '$25,001 - $50,000' in row['Income']:\n",
    "            matrix[2] = -0.6\n",
    "        elif 'under $25,000' in row['Income']:\n",
    "            matrix[2] = - 1\n",
    "        else:\n",
    "            matrix[2] = -3\n",
    "        #[1 0.5 0.1]\n",
    "        # HOUSEHOLD\n",
    "        columnNames[0,3] = 'HouseholdStatus'\n",
    "        if 'Married' in row['HouseholdStatus']:\n",
    "            matrix[3] = 1\n",
    "        elif 'Domestic' in row['HouseholdStatus']:\n",
    "            matrix[3] = 0.5\n",
    "        elif 'Single' in row['HouseholdStatus']:\n",
    "            matrix[3] = -1\n",
    "        else:\n",
    "            matrix[3] = -3\n",
    "        \n",
    "        # HAS KIDS OR NOT\n",
    "        columnNames[0,4] = 'Kids'\n",
    "        if 'w/' in row['HouseholdStatus']:\n",
    "            matrix[4] = 1\n",
    "        elif 'no' in row['HouseholdStatus']:\n",
    "            matrix[4] = -1\n",
    "        else:\n",
    "            matrix[4] = -3\n",
    "            \n",
    "        #[1 0.9 0.7 0.6 0.5 0.25 0.1]\n",
    "        # EDUCATION\n",
    "        columnNames[0,5] = 'EducationLevel'\n",
    "        if 'Doctoral' in row['EducationLevel']:\n",
    "            matrix[5] = 1\n",
    "        elif 'Master' in row['EducationLevel']:\n",
    "            matrix[5] = 0.8\n",
    "        elif 'Bachelor' in row['EducationLevel']:\n",
    "            matrix[5] = 0.6\n",
    "        elif 'Undergraduate' in row['EducationLevel']:\n",
    "            matrix[5] = 0.5\n",
    "        elif 'Associate' in row['EducationLevel']:\n",
    "            matrix[5] = 0.3\n",
    "        elif 'High School Diploma' in row['EducationLevel']:\n",
    "            matrix[5] = -0.25\n",
    "        elif 'K-12' in row['EducationLevel']:\n",
    "            matrix[5] = -1\n",
    "        else:\n",
    "            matrix[5] = -3\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "#         print(row['YOB'])\n",
    "#         if \"w/kids\" in row['HouseholdStatus']:\n",
    "#             print(\"HEY!!!\")\n",
    "\n",
    "        nextIndex = 6\n",
    "        for col in row:\n",
    "            if col in ['USER_ID', 'YOB', 'Gender', 'Income', 'HouseholdStatus', 'EducationLevel','Party']:\n",
    "                continue\n",
    "            if row[col] in ['Yes', 'Check!', 'Optimist', 'Mom', 'Rent', 'Yay people!', 'Online', 'Yes!', 'Socialize', 'Cautious', 'Mac', 'Supportive', 'Tunes', 'People', 'TMI', 'Start', 'Circumstances', 'A.M.', 'Happy', 'Hot headed', 'Standard hours', 'Idealist', 'Giving', 'Study first', 'Science', 'Public']:\n",
    "                matrix[nextIndex] = 1\n",
    "            elif row[col] in ['No', 'Only-child', 'Nope', 'Pessimist', 'Dad', 'Own', 'Grrr people', 'In-person', 'Umm...', 'Space', 'Risk-friendly', 'PC', 'Demanding', 'Talk', 'Technology', 'Mysterious', 'End', 'Me', 'P.M.', 'Right', 'Cool headed', 'Odd hours', 'Pragmatist', 'Receiving', 'Try first', 'Art', 'Private']:\n",
    "                matrix[nextIndex] = -1\n",
    "            else:\n",
    "                matrix[nextIndex] = -3\n",
    "            columnNames[0,nextIndex] = col\n",
    "            nextIndex += 1\n",
    "            \n",
    "        try:\n",
    "            partyAff = row['Party']\n",
    "            columnNames[0,nextIndex] = 'Party'\n",
    "            if 'Dem' in row['Party']:\n",
    "                matrix[nextIndex] = 1\n",
    "                outputs[line_count] = 1\n",
    "            elif 'Rep' in row['Party']:\n",
    "                matrix[nextIndex] = 0\n",
    "                outputs[line_count] = 0\n",
    "            else:\n",
    "                matrix[nextIndex] = -1\n",
    "                outputs[line_count] = -1\n",
    "        except:\n",
    "            matrix[nextIndex] = -1\n",
    "        \n",
    "        \n",
    "    \n",
    "        matrices[line_count,:] = matrix\n",
    "        line_count +=1\n",
    "        if line_count >= noTrainingExamples:\n",
    "            break\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YOB  Gender  Income  HouseholdStatus  Kids  EducationLevel  Q124742  \\\n",
      "0 -0.12     1.0    -3.0              1.0   1.0           -3.00     -1.0   \n",
      "1  0.20    -1.0     1.0              0.5   1.0            0.60     -3.0   \n",
      "2  0.47     1.0     0.2             -1.0  -1.0           -0.25     -3.0   \n",
      "3  0.33     1.0     0.6              1.0   1.0            0.60     -1.0   \n",
      "4  0.34    -1.0    -0.2              1.0   1.0           -0.25     -1.0   \n",
      "\n",
      "   Q124122  Q123464  Q123621  ...    Q99716  Q99581  Q99480  Q98869  Q98578  \\\n",
      "0     -3.0     -1.0     -1.0  ...      -1.0    -1.0    -3.0    -1.0    -3.0   \n",
      "1      1.0     -1.0     -1.0  ...      -3.0    -3.0    -1.0    -1.0    -1.0   \n",
      "2      1.0      1.0     -1.0  ...      -1.0    -1.0    -1.0     1.0    -1.0   \n",
      "3      1.0     -1.0      1.0  ...      -1.0    -1.0     1.0     1.0    -1.0   \n",
      "4      1.0     -1.0     -1.0  ...      -1.0    -1.0     1.0    -1.0    -1.0   \n",
      "\n",
      "   Q98059  Q98078  Q98197  Q96024  Party  \n",
      "0    -1.0    -1.0    -1.0     1.0    1.0  \n",
      "1    -1.0     1.0    -1.0    -1.0    1.0  \n",
      "2     1.0    -1.0     1.0    -1.0    0.0  \n",
      "3     1.0    -1.0    -1.0     1.0    1.0  \n",
      "4     1.0    -1.0    -1.0     1.0    0.0  \n",
      "\n",
      "[5 rows x 108 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(data=matrices,\n",
    "                   columns=columnNames[0,:])\n",
    "#data.to_csv('rawinput.csv', header=False,index=False)\n",
    "#csv = pd.read_csv(\"pca2.csv\").values\n",
    "\n",
    "#data = pd.DataFrame(data=csv,columns=columnNames[0,:])\n",
    "#data = data[data.YOB !=0]\n",
    "#data = data[data.Gender!=0]\n",
    "#data = data[data.HouseholdStatus !=0]\n",
    "#data = data[data.Kids !=0]\n",
    "#data = data[data.EducationLevel<0]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YOB  Gender  Income  HouseholdStatus  Kids  EducationLevel  Q124742  \\\n",
      "0 -0.12     1.0    -3.0              1.0   1.0           -3.00     -1.0   \n",
      "1  0.20    -1.0     1.0              0.5   1.0            0.60     -3.0   \n",
      "2  0.47     1.0     0.2             -1.0  -1.0           -0.25     -3.0   \n",
      "3  0.33     1.0     0.6              1.0   1.0            0.60     -1.0   \n",
      "4  0.34    -1.0    -0.2              1.0   1.0           -0.25     -1.0   \n",
      "\n",
      "   Q124122  Q123464  Q123621  ...    Q99716  Q99581  Q99480  Q98869  Q98578  \\\n",
      "0     -3.0     -1.0     -1.0  ...      -1.0    -1.0    -3.0    -1.0    -3.0   \n",
      "1      1.0     -1.0     -1.0  ...      -3.0    -3.0    -1.0    -1.0    -1.0   \n",
      "2      1.0      1.0     -1.0  ...      -1.0    -1.0    -1.0     1.0    -1.0   \n",
      "3      1.0     -1.0      1.0  ...      -1.0    -1.0     1.0     1.0    -1.0   \n",
      "4      1.0     -1.0     -1.0  ...      -1.0    -1.0     1.0    -1.0    -1.0   \n",
      "\n",
      "   Q98059  Q98078  Q98197  Q96024  Party  \n",
      "0    -1.0    -1.0    -1.0     1.0    1.0  \n",
      "1    -1.0     1.0    -1.0    -1.0    1.0  \n",
      "2     1.0    -1.0     1.0    -1.0    0.0  \n",
      "3     1.0    -1.0    -1.0     1.0    1.0  \n",
      "4     1.0    -1.0    -1.0     1.0    0.0  \n",
      "\n",
      "[5 rows x 108 columns]\n"
     ]
    }
   ],
   "source": [
    "#data = data.loc[data['Q115611'] == -1]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # import tensorflow as tf\n",
    "# %matplotlib inline\n",
    "# # import os\n",
    "# # os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #for training on gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5568, 108)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YOB  Gender  Income  HouseholdStatus  Kids  EducationLevel  Q124742  \\\n",
      "0 -0.12     1.0    -3.0              1.0   1.0           -3.00     -1.0   \n",
      "1  0.20    -1.0     1.0              0.5   1.0            0.60     -3.0   \n",
      "2  0.47     1.0     0.2             -1.0  -1.0           -0.25     -3.0   \n",
      "3  0.33     1.0     0.6              1.0   1.0            0.60     -1.0   \n",
      "4  0.34    -1.0    -0.2              1.0   1.0           -0.25     -1.0   \n",
      "\n",
      "   Q124122  Q123464  Q123621   ...    Q100010  Q99716  Q99581  Q99480  Q98869  \\\n",
      "0     -3.0     -1.0     -1.0   ...        1.0    -1.0    -1.0    -3.0    -1.0   \n",
      "1      1.0     -1.0     -1.0   ...       -3.0    -3.0    -3.0    -1.0    -1.0   \n",
      "2      1.0      1.0     -1.0   ...        1.0    -1.0    -1.0    -1.0     1.0   \n",
      "3      1.0     -1.0      1.0   ...       -1.0    -1.0    -1.0     1.0     1.0   \n",
      "4      1.0     -1.0     -1.0   ...        1.0    -1.0    -1.0     1.0    -1.0   \n",
      "\n",
      "   Q98578  Q98059  Q98078  Q98197  Q96024  \n",
      "0    -3.0    -1.0    -1.0    -1.0     1.0  \n",
      "1    -1.0    -1.0     1.0    -1.0    -1.0  \n",
      "2    -1.0     1.0    -1.0     1.0    -1.0  \n",
      "3    -1.0     1.0    -1.0    -1.0     1.0  \n",
      "4    -1.0     1.0    -1.0    -1.0     1.0  \n",
      "\n",
      "[5 rows x 107 columns]\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    0.0\n",
      "3    1.0\n",
      "4    0.0\n",
      "Name: Party, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "X = data.drop('Party', axis=1)\n",
    "y = data['Party']\n",
    "\n",
    "X.to_csv('input.csv', header=False,index=False)\n",
    "X.to_csv('inputlabel.csv')\n",
    "y.to_csv('label.csv', index=False)\n",
    "\n",
    "\n",
    "csv = pandas.read_csv(\"pca.csv\").values\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0422 16:16:57.550451 4407268800 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "import os\n",
    "# import pandas as pd\n",
    "import re\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4462\n",
      "1106\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#0.8 or 0.33\n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "train_data = data[msk]\n",
    "#train_data = data\n",
    "#test_data = data\n",
    "test_data = data[~msk]\n",
    "#print(len(train_data))\n",
    "#print(len(test_data))\n",
    "\n",
    "#for s in columnNames1[0,:]:\n",
    "#    train_data = train_data.loc[train_data[s] != 0]\n",
    "#test_data = data.loc[data['Q110740'] > -1]\n",
    "\n",
    "#train_data = data.loc[data['Q115611'] == -1]\n",
    "#test_data = data.loc[data['Q115611'] > -1]\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "\n",
    "# Training input on the whole training set with no limit on training epochs.\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    train_data, train_data[\"Party\"], num_epochs=None, shuffle=True)\n",
    "\n",
    "# Prediction on the whole training set.\n",
    "predict_train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    train_data, train_data[\"Party\"], shuffle=False)\n",
    "# Prediction on the test set.\n",
    "predict_test_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    test_data, test_data[\"Party\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:16:58.600358 4407268800 estimator.py:1739] Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmpwue9d6a2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:16:58.605360 4407268800 estimator.py:1760] Using temporary folder as model directory: /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmpwue9d6a2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmpwue9d6a2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a2d157898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:16:58.607841 4407268800 estimator.py:201] Using config: {'_model_dir': '/var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmpwue9d6a2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a2d157898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(key = key) for key in X_train.columns]\n",
    "#estimator = tf.estimator.DNNClassifier(\n",
    " #               hidden_units=[50,25,25],\n",
    "  #              feature_columns=feature_columns,\n",
    "   #             n_classes=2,\n",
    "    #            optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))\n",
    "\n",
    "#estimator = tf.estimator.DNNClassifier(\n",
    " #               hidden_units=[50,50,25],\n",
    "  #              feature_columns=feature_columns,\n",
    "   #             n_classes=2,\n",
    "    #            optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "     # learning_rate=0.003,\n",
    "     # l1_regularization_strength=0.01\n",
    "    #))\n",
    "    \n",
    "    #60 60 60/ 0.05\n",
    "    # 50 50 25 l2_regularization_strength=0.001\n",
    "    \n",
    "estimator = tf.estimator.DNNClassifier(\n",
    "               hidden_units=[50,50,25],\n",
    "               feature_columns=feature_columns,\n",
    "               n_classes=2,\n",
    "                optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "     learning_rate=0.003, l2_regularization_strength=0.001\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier object at 0x1a2d157668>\n"
     ]
    }
   ],
   "source": [
    "print(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:16:58.659417 4407268800 deprecation.py:323] From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:16:58.808039 4407268800 deprecation.py:323] From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:16:58.811535 4407268800 deprecation.py:323] From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:16:58.829972 4407268800 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:16:58.868561 4407268800 deprecation.py:323] From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:16:59.999632 4407268800 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:00.001277 4407268800 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:00.584474 4407268800 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:00.788357 4407268800 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:00.822661 4407268800 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:17:00.872542 4407268800 deprecation.py:323] From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmpwue9d6a2/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:01.978458 4407268800 basic_session_run_hooks.py:594] Saving checkpoints for 0 into /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmpwue9d6a2/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 91.78406, step = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:02.636109 4407268800 basic_session_run_hooks.py:249] loss = 91.78406, step = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 41.7873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:05.027940 4407268800 basic_session_run_hooks.py:680] global_step/sec: 41.7873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 88.18592, step = 101 (2.397 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:05.033231 4407268800 basic_session_run_hooks.py:247] loss = 88.18592, step = 101 (2.397 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 67.3827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:06.512011 4407268800 basic_session_run_hooks.py:680] global_step/sec: 67.3827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 85.729256, step = 201 (1.481 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:06.513814 4407268800 basic_session_run_hooks.py:247] loss = 85.729256, step = 201 (1.481 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 70.1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:07.938348 4407268800 basic_session_run_hooks.py:680] global_step/sec: 70.1112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 82.60651, step = 301 (1.427 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:07.940802 4407268800 basic_session_run_hooks.py:247] loss = 82.60651, step = 301 (1.427 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 76.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:09.254042 4407268800 basic_session_run_hooks.py:680] global_step/sec: 76.0036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 87.19561, step = 401 (1.316 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:09.256646 4407268800 basic_session_run_hooks.py:247] loss = 87.19561, step = 401 (1.316 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 54.6425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:11.084307 4407268800 basic_session_run_hooks.py:680] global_step/sec: 54.6425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 79.41153, step = 501 (1.831 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:11.088119 4407268800 basic_session_run_hooks.py:247] loss = 79.41153, step = 501 (1.831 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 64.0744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:12.644812 4407268800 basic_session_run_hooks.py:680] global_step/sec: 64.0744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 79.90295, step = 601 (1.559 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:12.647397 4407268800 basic_session_run_hooks.py:247] loss = 79.90295, step = 601 (1.559 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 70.1227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:14.070874 4407268800 basic_session_run_hooks.py:680] global_step/sec: 70.1227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 80.8038, step = 701 (1.426 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:14.073919 4407268800 basic_session_run_hooks.py:247] loss = 80.8038, step = 701 (1.426 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 62.6986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:15.665840 4407268800 basic_session_run_hooks.py:680] global_step/sec: 62.6986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 76.422424, step = 801 (1.595 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:15.668853 4407268800 basic_session_run_hooks.py:247] loss = 76.422424, step = 801 (1.595 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 67.6177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:17.144761 4407268800 basic_session_run_hooks.py:680] global_step/sec: 67.6177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 75.453995, step = 901 (1.478 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:17.147232 4407268800 basic_session_run_hooks.py:247] loss = 75.453995, step = 901 (1.478 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmpwue9d6a2/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:18.767494 4407268800 basic_session_run_hooks.py:594] Saving checkpoints for 1000 into /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmpwue9d6a2/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 82.460495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:19.122779 4407268800 estimator.py:359] Loss for final step: 82.460495.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x1a2d157668>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#int(len(train_data)/3))\n",
    "estimator.train(input_fn=train_input_fn, steps= 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:19.211858 4407268800 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:2002: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:17:20.696123 4407268800 deprecation.py:323] From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:2002: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:17:21.036725 4407268800 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:17:21.062977 4407268800 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:21.084954 4407268800 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-04-22T07:17:21Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:21.108453 4407268800 evaluation.py:257] Starting evaluation at 2020-04-22T07:17:21Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:21.232751 4407268800 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:17:21.234429 4407268800 deprecation.py:323] From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmpwue9d6a2/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:21.236726 4407268800 saver.py:1270] Restoring parameters from /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmpwue9d6a2/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:21.341952 4407268800 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:21.384306 4407268800 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-04-22-07:17:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:22.465687 4407268800 evaluation.py:277] Finished evaluation at 2020-04-22-07:17:22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.691394, accuracy_baseline = 0.5338413, auc = 0.7640956, auc_precision_recall = 0.7818001, average_loss = 0.5926029, global_step = 1000, label/mean = 0.5338413, loss = 75.5484, precision = 0.6835952, prediction/mean = 0.5352476, recall = 0.7854744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:22.467110 4407268800 estimator.py:1979] Saving dict for global step 1000: accuracy = 0.691394, accuracy_baseline = 0.5338413, auc = 0.7640956, auc_precision_recall = 0.7818001, average_loss = 0.5926029, global_step = 1000, label/mean = 0.5338413, loss = 75.5484, precision = 0.6835952, prediction/mean = 0.5352476, recall = 0.7854744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmpwue9d6a2/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:22.809216 4407268800 estimator.py:2039] Saving 'checkpoint_path' summary for global step 1000: /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmpwue9d6a2/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:22.880465 4407268800 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:17:24.438140 4407268800 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:17:24.456887 4407268800 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:24.478254 4407268800 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-04-22T07:17:24Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:24.499202 4407268800 evaluation.py:257] Starting evaluation at 2020-04-22T07:17:24Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:24.611070 4407268800 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmpwue9d6a2/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:24.613169 4407268800 saver.py:1270] Restoring parameters from /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmpwue9d6a2/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:24.713700 4407268800 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:24.754688 4407268800 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-04-22-07:17:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:25.494216 4407268800 evaluation.py:277] Finished evaluation at 2020-04-22-07:17:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.5750452, accuracy_baseline = 0.5144665, auc = 0.6266916, auc_precision_recall = 0.65763205, average_loss = 0.6667986, global_step = 1000, label/mean = 0.5144665, loss = 81.94214, precision = 0.5720524, prediction/mean = 0.53650767, recall = 0.6906854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:25.495498 4407268800 estimator.py:1979] Saving dict for global step 1000: accuracy = 0.5750452, accuracy_baseline = 0.5144665, auc = 0.6266916, auc_precision_recall = 0.65763205, average_loss = 0.6667986, global_step = 1000, label/mean = 0.5144665, loss = 81.94214, precision = 0.5720524, prediction/mean = 0.53650767, recall = 0.6906854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmpwue9d6a2/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:17:25.496890 4407268800 estimator.py:2039] Saving 'checkpoint_path' summary for global step 1000: /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmpwue9d6a2/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.6913939714431763\n",
      "Test set accuracy: 0.5750452280044556\n"
     ]
    }
   ],
   "source": [
    "train_eval_result = estimator.evaluate(input_fn=predict_train_input_fn)\n",
    "test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)\n",
    "\n",
    "print(\"Training set accuracy: {accuracy}\".format(**train_eval_result))\n",
    "print(\"Test set accuracy: {accuracy}\".format(**test_eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/hub/tutorials/text_classification_with_tf_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16774167 -0.00630652  0.05887866 ... -0.03411975 -0.03138697\n",
      "   0.00255317]\n",
      " [-0.03336286 -0.22516507  0.06766329 ...  0.11863179 -0.10521383\n",
      "  -0.21574028]\n",
      " [-0.03984909 -0.08750537 -0.19238865 ...  0.16910052  0.00468452\n",
      "  -0.01263273]\n",
      " ...\n",
      " [-0.12265067  0.06975643 -0.16801949 ... -0.15094239 -0.12267663\n",
      "   0.06259913]\n",
      " [ 0.12012803 -0.13254757  0.16455144 ...  0.07356966  0.05081976\n",
      "   0.13208494]\n",
      " [ 0.18262972 -0.0602202   0.16140363 ... -0.00027862 -0.05964255\n",
      "   0.10298358]]\n",
      "[-0.00869458 -0.00767932 -0.00793333 -0.01171952  0.04001604  0.00991546\n",
      "  0.00984046  0.02880786 -0.02043341  0.01355649 -0.0101882  -0.00364264\n",
      " -0.00941688  0.01217523 -0.01416891  0.03828789  0.02275361 -0.0043982\n",
      " -0.003921   -0.00557932  0.01196789  0.03114657  0.00362657  0.01362878\n",
      "  0.01231646  0.01796517 -0.01285669  0.00824069 -0.01029303  0.02018647\n",
      "  0.02205429  0.00266382  0.0091964  -0.00357789 -0.00107566 -0.00481922\n",
      "  0.01133289  0.0032905   0.02577714  0.00263641  0.00833024  0.01884965\n",
      " -0.01403254 -0.00196275  0.00714004  0.02796229  0.00266755 -0.02487178\n",
      "  0.01426262 -0.02717318]\n"
     ]
    }
   ],
   "source": [
    "##hidden layer info\n",
    "#print(estimator.get_variable_value(\"dnn/hiddenlayer_0/kernel\"))\n",
    "#print(estimator.get_variable_value(\"dnn/hiddenlayer_0/bias\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
