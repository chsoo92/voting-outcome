{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('train2016.csv', mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    noTrainingExamples = 5568 # number of items in csv...  \n",
    "    noColumns = 108 # how many columns will we store... \n",
    "    line_count = 0\n",
    "    outputs = np.zeros(noTrainingExamples)\n",
    "    matrices = np.zeros((noTrainingExamples, noColumns))\n",
    "    columnNames = np.empty([1,noColumns], dtype=object)\n",
    "    userIDs = np.empty([1,noTrainingExamples])\n",
    "    for row in csv_reader:\n",
    "            \n",
    "        matrix = np.zeros(noColumns)\n",
    "#             matrix[0] = float(row['YOB'])\n",
    "        userIDs[0,line_count] = row['USER_ID']\n",
    "        # YOB\n",
    "        columnNames[0,0] = 'YOB'\n",
    "        maxv = 0\n",
    "        try:\n",
    "            matrix[0] = (((float(row['YOB'])%1900)/100)-0.5)\n",
    "        except ValueError:\n",
    "            matrix[0] = 0\n",
    "        \n",
    "        # GENDER\n",
    "        columnNames[0,1] = 'Gender'\n",
    "        if 'Male' in row['Gender']:\n",
    "            matrix[1] = 1\n",
    "        elif 'Female' in row['Gender']:\n",
    "            matrix[1] = -1\n",
    "        else:\n",
    "            matrix[1] = 0\n",
    "        \n",
    "        #  [1 0.6 0.2 -0.2 -0.6]\n",
    "        #INCOME\n",
    "        columnNames[0,2] = 'Income'\n",
    "        if 'over $150,000' in row['Income']:\n",
    "            matrix[2] = 1\n",
    "        elif '$100,001 - $150,000' in row['Income']:\n",
    "            matrix[2] = 0.6\n",
    "        elif '$75,000 - $100,000' in row['Income']:\n",
    "            matrix[2] = 0.2\n",
    "        elif '$50,000 - $74,999' in row['Income']:\n",
    "            matrix[2] = -0.2\n",
    "        elif '$25,001 - $50,000' in row['Income']:\n",
    "            matrix[2] = -0.6\n",
    "        elif 'under $25,000' in row['Income']:\n",
    "            matrix[2] = - 1\n",
    "        else:\n",
    "            matrix[2] = 0\n",
    "        #[1 0.5 0.1]\n",
    "        # HOUSEHOLD\n",
    "        columnNames[0,3] = 'HouseholdStatus'\n",
    "        if 'Married' in row['HouseholdStatus']:\n",
    "            matrix[3] = 1\n",
    "        elif 'Domestic' in row['HouseholdStatus']:\n",
    "            matrix[3] = 0.5\n",
    "        elif 'Single' in row['HouseholdStatus']:\n",
    "            matrix[3] = -1\n",
    "        else:\n",
    "            matrix[3] = 0\n",
    "        \n",
    "        # HAS KIDS OR NOT\n",
    "        columnNames[0,4] = 'Kids'\n",
    "        if 'w/' in row['HouseholdStatus']:\n",
    "            matrix[4] = 1\n",
    "        elif 'no' in row['HouseholdStatus']:\n",
    "            matrix[4] = -1\n",
    "        else:\n",
    "            matrix[4] = 0\n",
    "            \n",
    "        #[1 0.9 0.7 0.6 0.5 0.25 0.1]\n",
    "        # EDUCATION\n",
    "        columnNames[0,5] = 'EducationLevel'\n",
    "        if 'Doctoral' in row['EducationLevel']:\n",
    "            matrix[5] = 1\n",
    "        elif 'Master' in row['EducationLevel']:\n",
    "            matrix[5] = 0.8\n",
    "        elif 'Bachelor' in row['EducationLevel']:\n",
    "            matrix[5] = 0.6\n",
    "        elif 'Undergraduate' in row['EducationLevel']:\n",
    "            matrix[5] = 0.5\n",
    "        elif 'Associate' in row['EducationLevel']:\n",
    "            matrix[5] = 0.3\n",
    "        elif 'High School Diploma' in row['EducationLevel']:\n",
    "            matrix[5] = -0.25\n",
    "        elif 'K-12' in row['EducationLevel']:\n",
    "            matrix[5] = -1\n",
    "        else:\n",
    "            matrix[5] = 0\n",
    "        \n",
    "        nextIndex = 6\n",
    "        for col in row:\n",
    "            if col in ['USER_ID', 'YOB', 'Gender', 'Income', 'HouseholdStatus', 'EducationLevel','Party']:\n",
    "                continue\n",
    "            if row[col] in ['Yes', 'Check!', 'Optimist', 'Mom', 'Rent', 'Yay people!', 'Online', 'Yes!', 'Socialize', 'Cautious', 'Mac', 'Supportive', 'Tunes', 'People', 'TMI', 'Start', 'Circumstances', 'A.M.', 'Happy', 'Hot headed', 'Standard hours', 'Idealist', 'Giving', 'Study first', 'Science', 'Public']:\n",
    "                matrix[nextIndex] = 1\n",
    "            elif row[col] in ['No', 'Only-child', 'Nope', 'Pessimist', 'Dad', 'Own', 'Grrr people', 'In-person', 'Umm...', 'Space', 'Risk-friendly', 'PC', 'Demanding', 'Talk', 'Technology', 'Mysterious', 'End', 'Me', 'P.M.', 'Right', 'Cool headed', 'Odd hours', 'Pragmatist', 'Receiving', 'Try first', 'Art', 'Private']:\n",
    "                matrix[nextIndex] = -1\n",
    "            else:\n",
    "                matrix[nextIndex] = 0\n",
    "            columnNames[0,nextIndex] = col\n",
    "            nextIndex += 1\n",
    "            \n",
    "        try:\n",
    "            partyAff = row['Party']\n",
    "            columnNames[0,nextIndex] = 'Party'\n",
    "            if 'Dem' in row['Party']:\n",
    "                matrix[nextIndex] = 1\n",
    "                outputs[line_count] = 1\n",
    "            elif 'Rep' in row['Party']:\n",
    "                matrix[nextIndex] = 0\n",
    "                outputs[line_count] = 0\n",
    "            else:\n",
    "                matrix[nextIndex] = -1\n",
    "                outputs[line_count] = -1\n",
    "        except:\n",
    "            matrix[nextIndex] = -1\n",
    "        \n",
    "        \n",
    "    \n",
    "        matrices[line_count,:] = matrix\n",
    "        line_count +=1\n",
    "        if line_count >= noTrainingExamples:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YOB  Gender  Income  HouseholdStatus  Kids  EducationLevel  Q124742  \\\n",
      "0 -0.12     1.0     0.0              1.0   1.0            0.00     -1.0   \n",
      "1  0.20    -1.0     1.0              0.5   1.0            0.60      0.0   \n",
      "2  0.47     1.0     0.2             -1.0  -1.0           -0.25      0.0   \n",
      "3  0.33     1.0     0.6              1.0   1.0            0.60     -1.0   \n",
      "4  0.34    -1.0    -0.2              1.0   1.0           -0.25     -1.0   \n",
      "\n",
      "   Q124122  Q123464  Q123621  ...    Q99716  Q99581  Q99480  Q98869  Q98578  \\\n",
      "0      0.0     -1.0     -1.0  ...      -1.0    -1.0     0.0    -1.0     0.0   \n",
      "1      1.0     -1.0     -1.0  ...       0.0     0.0    -1.0    -1.0    -1.0   \n",
      "2      1.0      1.0     -1.0  ...      -1.0    -1.0    -1.0     1.0    -1.0   \n",
      "3      1.0     -1.0      1.0  ...      -1.0    -1.0     1.0     1.0    -1.0   \n",
      "4      1.0     -1.0     -1.0  ...      -1.0    -1.0     1.0    -1.0    -1.0   \n",
      "\n",
      "   Q98059  Q98078  Q98197  Q96024  Party  \n",
      "0    -1.0    -1.0    -1.0     1.0    1.0  \n",
      "1    -1.0     1.0    -1.0    -1.0    1.0  \n",
      "2     1.0    -1.0     1.0    -1.0    0.0  \n",
      "3     1.0    -1.0    -1.0     1.0    1.0  \n",
      "4     1.0    -1.0    -1.0     1.0    0.0  \n",
      "\n",
      "[5 rows x 108 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(data=matrices,\n",
    "                   columns=columnNames[0,:])\n",
    "#data.to_csv('rawinput.csv', header=False,index=False)\n",
    "#csv = pd.read_csv(\"pca2.csv\").values\n",
    "\n",
    "\n",
    "## for manipulating data\n",
    "#data = pd.DataFrame(data=csv,columns=columnNames[0,:])\n",
    "#data = data[data.YOB !=0]\n",
    "#data = data[data.Gender!=0]\n",
    "#data = data[data.HouseholdStatus !=0]\n",
    "#data = data[data.Kids !=0]\n",
    "#data = data[data.EducationLevel<0]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YOB  Gender  Income  HouseholdStatus  Kids  EducationLevel  Q124742  \\\n",
      "0 -0.12     1.0     0.0              1.0   1.0            0.00     -1.0   \n",
      "1  0.20    -1.0     1.0              0.5   1.0            0.60      0.0   \n",
      "2  0.47     1.0     0.2             -1.0  -1.0           -0.25      0.0   \n",
      "3  0.33     1.0     0.6              1.0   1.0            0.60     -1.0   \n",
      "4  0.34    -1.0    -0.2              1.0   1.0           -0.25     -1.0   \n",
      "\n",
      "   Q124122  Q123464  Q123621  ...    Q99716  Q99581  Q99480  Q98869  Q98578  \\\n",
      "0      0.0     -1.0     -1.0  ...      -1.0    -1.0     0.0    -1.0     0.0   \n",
      "1      1.0     -1.0     -1.0  ...       0.0     0.0    -1.0    -1.0    -1.0   \n",
      "2      1.0      1.0     -1.0  ...      -1.0    -1.0    -1.0     1.0    -1.0   \n",
      "3      1.0     -1.0      1.0  ...      -1.0    -1.0     1.0     1.0    -1.0   \n",
      "4      1.0     -1.0     -1.0  ...      -1.0    -1.0     1.0    -1.0    -1.0   \n",
      "\n",
      "   Q98059  Q98078  Q98197  Q96024  Party  \n",
      "0    -1.0    -1.0    -1.0     1.0    1.0  \n",
      "1    -1.0     1.0    -1.0    -1.0    1.0  \n",
      "2     1.0    -1.0     1.0    -1.0    0.0  \n",
      "3     1.0    -1.0    -1.0     1.0    1.0  \n",
      "4     1.0    -1.0    -1.0     1.0    0.0  \n",
      "\n",
      "[5 rows x 108 columns]\n"
     ]
    }
   ],
   "source": [
    "#data = data.loc[data['Q115611'] == -1]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # import tensorflow as tf\n",
    "# %matplotlib inline\n",
    "# # import os\n",
    "# # os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #for training on gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5568, 108)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "X = data.drop('Party', axis=1)\n",
    "y = data['Party']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0422 16:20:42.479877 4536202688 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "import os\n",
    "# import pandas as pd\n",
    "import re\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4462\n",
      "1106\n"
     ]
    }
   ],
   "source": [
    "#0.8 or 0.33\n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "train_data = data[msk]\n",
    "#train_data = data\n",
    "#test_data = data\n",
    "test_data = data[~msk]\n",
    "#print(len(train_data))\n",
    "#print(len(test_data))\n",
    "\n",
    "#for s in columnNames1[0,:]:\n",
    "#    train_data = train_data.loc[train_data[s] != 0]\n",
    "#test_data = data.loc[data['Q110740'] > -1]\n",
    "\n",
    "#train_data = data.loc[data['Q115611'] == -1]\n",
    "#test_data = data.loc[data['Q115611'] > -1]\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "\n",
    "# Training input on the whole training set with no limit on training epochs.\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    train_data, train_data[\"Party\"], num_epochs=None, shuffle=True)\n",
    "\n",
    "# Prediction on the whole training set.\n",
    "predict_train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    train_data, train_data[\"Party\"], shuffle=False)\n",
    "# Prediction on the test set.\n",
    "predict_test_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    test_data, test_data[\"Party\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Party', axis=1)\n",
    "y = data['Party']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:43.834245 4536202688 estimator.py:1739] Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmp4t6v0b84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:20:43.840682 4536202688 estimator.py:1760] Using temporary folder as model directory: /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmp4t6v0b84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmp4t6v0b84', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a347aee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:43.844272 4536202688 estimator.py:201] Using config: {'_model_dir': '/var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmp4t6v0b84', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a347aee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(key = key) for key in X_train.columns]\n",
    "#estimator = tf.estimator.DNNClassifier(\n",
    " #               hidden_units=[50,25,25],\n",
    "  #              feature_columns=feature_columns,\n",
    "   #             n_classes=2,\n",
    "    #            optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))\n",
    "\n",
    "#estimator = tf.estimator.DNNClassifier(\n",
    " #               hidden_units=[50,50,25],\n",
    "  #              feature_columns=feature_columns,\n",
    "   #             n_classes=2,\n",
    "    #            optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "     # learning_rate=0.003,\n",
    "     # l1_regularization_strength=0.01\n",
    "    #))\n",
    "    \n",
    "    #60 60 60/ 0.05\n",
    "    # 50 50 25 l2_regularization_strength=0.001\n",
    "estimator = tf.estimator.DNNClassifier(\n",
    "               hidden_units=[50,50,25],\n",
    "               feature_columns=feature_columns,\n",
    "               n_classes=2,\n",
    "                optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "     learning_rate=0.003, l2_regularization_strength=0.001\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier object at 0x1a347aec18>\n"
     ]
    }
   ],
   "source": [
    "print(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:20:43.892184 4536202688 deprecation.py:323] From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:20:44.121859 4536202688 deprecation.py:323] From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:20:44.125381 4536202688 deprecation.py:323] From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:44.140092 4536202688 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:20:44.160655 4536202688 deprecation.py:323] From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:45.587431 4536202688 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:45.589448 4536202688 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:46.024248 4536202688 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:46.135144 4536202688 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:46.159600 4536202688 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:20:46.206089 4536202688 deprecation.py:323] From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmp4t6v0b84/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:46.986855 4536202688 basic_session_run_hooks.py:594] Saving checkpoints for 0 into /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmp4t6v0b84/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 88.652664, step = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:47.434710 4536202688 basic_session_run_hooks.py:249] loss = 88.652664, step = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 46.9071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:49.566259 4536202688 basic_session_run_hooks.py:680] global_step/sec: 46.9071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 81.65726, step = 101 (2.134 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:49.568275 4536202688 basic_session_run_hooks.py:247] loss = 81.65726, step = 101 (2.134 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 70.9761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:50.975181 4536202688 basic_session_run_hooks.py:680] global_step/sec: 70.9761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 79.12341, step = 201 (1.409 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:50.977190 4536202688 basic_session_run_hooks.py:247] loss = 79.12341, step = 201 (1.409 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 77.4823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:52.265834 4536202688 basic_session_run_hooks.py:680] global_step/sec: 77.4823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 81.62787, step = 301 (1.291 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:52.267765 4536202688 basic_session_run_hooks.py:247] loss = 81.62787, step = 301 (1.291 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 77.668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:53.553329 4536202688 basic_session_run_hooks.py:680] global_step/sec: 77.668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 75.75994, step = 401 (1.288 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:53.555290 4536202688 basic_session_run_hooks.py:247] loss = 75.75994, step = 401 (1.288 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 63.5603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:55.126641 4536202688 basic_session_run_hooks.py:680] global_step/sec: 63.5603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 73.39894, step = 501 (1.580 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:55.134849 4536202688 basic_session_run_hooks.py:247] loss = 73.39894, step = 501 (1.580 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 79.4235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:56.385735 4536202688 basic_session_run_hooks.py:680] global_step/sec: 79.4235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 73.50902, step = 601 (1.254 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:56.388853 4536202688 basic_session_run_hooks.py:247] loss = 73.50902, step = 601 (1.254 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 79.4579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:57.644295 4536202688 basic_session_run_hooks.py:680] global_step/sec: 79.4579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 77.63658, step = 701 (1.257 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:57.646041 4536202688 basic_session_run_hooks.py:247] loss = 77.63658, step = 701 (1.257 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 44.1655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:59.908486 4536202688 basic_session_run_hooks.py:680] global_step/sec: 44.1655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 66.883865, step = 801 (2.267 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:20:59.912871 4536202688 basic_session_run_hooks.py:247] loss = 66.883865, step = 801 (2.267 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 50.6523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:01.882722 4536202688 basic_session_run_hooks.py:680] global_step/sec: 50.6523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 72.30706, step = 901 (1.973 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:01.885818 4536202688 basic_session_run_hooks.py:247] loss = 72.30706, step = 901 (1.973 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmp4t6v0b84/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:03.608612 4536202688 basic_session_run_hooks.py:594] Saving checkpoints for 1000 into /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmp4t6v0b84/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 82.07913.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:03.964778 4536202688 estimator.py:359] Loss for final step: 82.07913.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x1a347aec18>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#int(len(train_data)/3))\n",
    "estimator.train(input_fn=train_input_fn, steps= 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:04.107963 4536202688 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:2002: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:21:05.690036 4536202688 deprecation.py:323] From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:2002: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:21:06.392735 4536202688 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:21:06.480726 4536202688 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:06.515290 4536202688 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-04-22T07:21:06Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:06.543887 4536202688 evaluation.py:257] Starting evaluation at 2020-04-22T07:21:06Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:06.670068 4536202688 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:21:06.672827 4536202688 deprecation.py:323] From /Users/suhwanchoi/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmp4t6v0b84/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:06.678802 4536202688 saver.py:1270] Restoring parameters from /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmp4t6v0b84/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:06.823621 4536202688 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:06.880751 4536202688 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-04-22-07:21:08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:08.174988 4536202688 evaluation.py:277] Finished evaluation at 2020-04-22-07:21:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.7185119, accuracy_baseline = 0.5396683, auc = 0.7915815, auc_precision_recall = 0.8161898, average_loss = 0.5577473, global_step = 1000, label/mean = 0.5396683, loss = 71.10481, precision = 0.7309543, prediction/mean = 0.53425926, recall = 0.7570598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:08.176214 4536202688 estimator.py:1979] Saving dict for global step 1000: accuracy = 0.7185119, accuracy_baseline = 0.5396683, auc = 0.7915815, auc_precision_recall = 0.8161898, average_loss = 0.5577473, global_step = 1000, label/mean = 0.5396683, loss = 71.10481, precision = 0.7309543, prediction/mean = 0.53425926, recall = 0.7570598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmp4t6v0b84/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:08.606123 4536202688 estimator.py:2039] Saving 'checkpoint_path' summary for global step 1000: /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmp4t6v0b84/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:08.696776 4536202688 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:21:10.570065 4536202688 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 16:21:10.591791 4536202688 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:10.621998 4536202688 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-04-22T07:21:10Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:10.659024 4536202688 evaluation.py:257] Starting evaluation at 2020-04-22T07:21:10Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:10.816520 4536202688 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmp4t6v0b84/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:10.819354 4536202688 saver.py:1270] Restoring parameters from /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmp4t6v0b84/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:10.929134 4536202688 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:10.985661 4536202688 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-04-22-07:21:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:11.804301 4536202688 evaluation.py:277] Finished evaluation at 2020-04-22-07:21:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.6283906, accuracy_baseline = 0.50904155, auc = 0.66813374, auc_precision_recall = 0.64764386, average_loss = 0.66602665, global_step = 1000, label/mean = 0.49095842, loss = 81.847275, precision = 0.6089109, prediction/mean = 0.5347794, recall = 0.67955804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:11.806251 4536202688 estimator.py:1979] Saving dict for global step 1000: accuracy = 0.6283906, accuracy_baseline = 0.50904155, auc = 0.66813374, auc_precision_recall = 0.64764386, average_loss = 0.66602665, global_step = 1000, label/mean = 0.49095842, loss = 81.847275, precision = 0.6089109, prediction/mean = 0.5347794, recall = 0.67955804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmp4t6v0b84/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0422 16:21:11.807955 4536202688 estimator.py:2039] Saving 'checkpoint_path' summary for global step 1000: /var/folders/y9/7kjb4fj50lngbqcff3_4y4n40000gn/T/tmp4t6v0b84/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.7185118794441223\n",
      "Test set accuracy: 0.6283906102180481\n"
     ]
    }
   ],
   "source": [
    "train_eval_result = estimator.evaluate(input_fn=predict_train_input_fn)\n",
    "test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)\n",
    "\n",
    "print(\"Training set accuracy: {accuracy}\".format(**train_eval_result))\n",
    "print(\"Test set accuracy: {accuracy}\".format(**test_eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/hub/tutorials/text_classification_with_tf_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden layer info\n",
    "#print(estimator.get_variable_value(\"dnn/hiddenlayer_0/kernel\"))\n",
    "#print(estimator.get_variable_value(\"dnn/hiddenlayer_0/bias\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
